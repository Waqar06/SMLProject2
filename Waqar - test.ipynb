{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP90051 Project 2\n",
    "**Name:** *enter your name here*\n",
    "\n",
    "**Student ID:** *your id here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can add additional imports here\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "# Additional imports\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not edit this cell\n",
    "# load the data files (download from the LMS)\n",
    "embedded_images = np.load('images.npy')\n",
    "labels = np.load('labels.npy')\n",
    "\n",
    "# split into pool & testing\n",
    "X_pool, X_test, y_pool, y_test = train_test_split(embedded_images, labels, \n",
    "                                                  test_size=0.5, random_state=1234, shuffle=True)\n",
    "\n",
    "# sample a seed set\n",
    "np.random.seed(1234)\n",
    "label2id = defaultdict(list)\n",
    "for i, label in enumerate(y_pool):\n",
    "    label2id[label].append(i)\n",
    "seed_set = []\n",
    "for label, ids in label2id.items():\n",
    "    #print(label)\n",
    "    #print(np.random.choice(ids, size=10, replace=False))\n",
    "    seed_set.extend(np.random.choice(ids, size=10, replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_pool.shape #(9640, 1000)\n",
    "# for i in y_pool[:14]:\n",
    "#     print(i)\n",
    "# myset = set(y_pool)\n",
    "# print(len(myset)) # 30 unique labels \n",
    "#label2id\n",
    "\n",
    "#Helper Function\n",
    "def id2label(seed_id,ListLabel):\n",
    "    seed_set_label = []\n",
    "    for label, ids in ListLabel.items():\n",
    "        for seedid in seed_id:\n",
    "            if seedid in ids:\n",
    "                seed_set_label.append(label)  \n",
    "    return seed_set_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Applying logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_regression(X, y, **args):\n",
    " \n",
    "    from numpy import mean\n",
    "    from numpy import std\n",
    "    from sklearn.datasets import make_classification\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    # define dataset\n",
    "   \n",
    "    # define the multinomial logistic regression model\n",
    "    log_reg = LogisticRegression(multi_class='multinomial', solver='sag')\n",
    "    model = log_reg.fit(X, y)\n",
    "\n",
    "\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Accuracy: {}\".format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.3070539419087137\n",
      "C:\\Users\\Waqar\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "model1 = train_logistic_regression(X_pool[seed_set],seed_set_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_logistic_regression_accuracy(Xt, yt, model):\n",
    "    \"\"\"\n",
    "    Apply logistic regression prediction on dataset Xt and evaluate accuracy against yt,\n",
    "    returing the accuracy results as a scalar.\n",
    "    Xt: matrix of real values, size m x d\n",
    "    yt: vector of string labels, size m\n",
    "    \"\"\"\n",
    "    # your code here\n",
    "    y_pred = model.predict(Xt)\n",
    "    #score = model.score(Xt,yt)\n",
    "    #print('Test Accuracy Score', score)\n",
    "    #score = accuracy_score(yt, y_pred)\n",
    "    #print(\"Accuracy: {}\".format(accuracy_score(yt, y_pred)))\n",
    "    # print(\"Precision: {}\".format(precision_score(yt, y_pred)))\n",
    "    # print(\"Recall: {}\".format(recall_score(yt, y_pred)))\n",
    "    # evaluate the model and collect the scores\n",
    "    # define the model evaluation procedure\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    n_scores = cross_val_score(model, Xt, yt, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "    # report the model performance\n",
    "    return score\n",
    "    #print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here for training, evaluating & plotting results\n",
    "\n",
    "# Traning model 1 with seed_set -> Subest of y_pool.\n",
    "model1 = train_logistic_regression(X_pool[seed_set],seed_set)\n",
    "\n",
    "# Traning model 2 with max pool \n",
    "#model2 = train_logistic_regression(X_pool,y_pool)\n",
    "\n",
    "# Evaluation of models trained\n",
    "#evaluate_logistic_regression_accuracy(X_test,y_test,model1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation of models trained\n",
    "evaluate_logistic_regression_accuracy(X_test,y_test,model1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Active learning framework with Random selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_select(X, model, **args):\n",
    "    \"\"\"\n",
    "    Given an unlabelled dataset X, a matrix of n x d, and a model (not used)\n",
    "    returns a vector of scores of length n. Each entry reflects the priority \n",
    "    of the corresponding instance. Higher means better.\n",
    "    \"\"\"\n",
    "    # fill in\n",
    "\n",
    "    # Creating a score array using random numbers of length of X \n",
    "    scores = np.random.randint(1,len(X),len(X))\n",
    "    return scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_based_active_learning(X_pool, y_pool, seed_ids,\n",
    "                               train_func, select_func,\n",
    "                               max_size, batch_size, **args):\n",
    "    \"\"\"\n",
    "    Perform an active learning simulation, which starts by training on a seed set,\n",
    "    then iteratively applies the selection function to rank instances in the pool,\n",
    "    selects the top few instances which are included into the training set and the\n",
    "    process repeats. \n",
    "        X_pool: matrix of n x d\n",
    "        y_pool: vector of string labels, size n\n",
    "        seed_ids: initial labelled set set, as a list of indices [0..n-1] into pool\n",
    "        train_func: function which given (X, y, optional args) returns a trained model\n",
    "        select_func: function which given (X, optional args) returns a sequence of scores\n",
    "        max_size: stopping condition for active learning, when labelled data reaches given size\n",
    "        batch_size: number of instances to be labelled in each iteration\n",
    "        args: optional arguments passed to training and selection function\n",
    "    returns the sequence of trained models \n",
    "    \"\"\"\n",
    "\n",
    "    # 1: U = pool of unlabelled instances, {x} \n",
    "    U =  np.delete(X_pool,seed_ids, axis=0)\n",
    "    # 2: L = set of initial labelled instances, {hx,yi} \n",
    "    L = [X_pool[seed_ids],seed_ids]   # L = (x,y)  \n",
    "    # 3: b = number of instances to label in each step \n",
    "    b =  batch\n",
    "    # 4: for t = 1,2,...,T do \n",
    "    for i in range(1,45):  # Loop will run from 300 to 3000 Instances\n",
    "    # 5:  Î¸(t) = train(L) \n",
    "        Theta_model=train_func(L[0],L[1])\n",
    "        #########################  Accuracy Block #######################################\n",
    "        model_accuracy = evaluate_logistic_regression_accuracy(X_test,y_test,Theta_model)\n",
    "        print('Accuracy after query ',i)   \n",
    "        print('Mean Accuracy: %.3f (%.3f)' % (mean(model_accuracy), std(model_accuracy)))\n",
    "        #################################################################################\n",
    "    # 6:  score all instances in pool, r = select(U) \n",
    "        r = select_func(U,Theta_model)\n",
    "    # 7:  for all j â argmax(b,r) do \n",
    "        max_indices = np.argpartition(r,-b)[-b:]\n",
    "        for j in max_indices:\n",
    "    # 8:      reveal label y     \n",
    "    # 9:      add hxj,yji to L\n",
    "            L[0] = np.append(L[0],[X_pool[j]], axis=0)\n",
    "            L[1].append(j)\n",
    "            #print(\"seed set \",len(seed_set))\n",
    "            #print(\"seed id\",len(seed_ids))\n",
    "    # 10:     remove xj from U \n",
    "            U = np.delete(X_pool,L[1],axis=0)\n",
    "             #  Calculate and report our model's accuracy.                       \n",
    "    # 11:    end for \n",
    "    # 12: end for \n",
    "    # 13: return {Î¸(t)}T t=1\n",
    "    return Theta_model\n",
    "    ########################################## Not Part of Algo ########################\n",
    "    \n",
    "        \n",
    "     #  Calculate and report our model's accuracy.\n",
    "        #model_accuracy = evaluate_logistic_regression_accuracy(X_test,y_test,Theta_model)\n",
    "        #print('Accuracy after query {n}: {acc:0.4f}'.format(n=i + 1, acc=model_accuracy))\n",
    "    # # Save our model's performance for plotting.\n",
    "        #performance_history.append(model_accuracy)\n",
    "\n",
    "    ########################################## Not Part of Algo ########################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(seed_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 60\n",
    "max_size = 3000\n",
    "models_random = pool_based_active_learning(X_pool, y_pool, seed_set, \n",
    "                                    train_logistic_regression, random_select, \n",
    "                                    max_size, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here for evaluation of accuracy and plotting of results\n",
    "\n",
    "# NOTE: Make Graphs and Check Evaluation Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Uncertainty sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_entropy_select(X, model, **args):\n",
    "    \"\"\"\n",
    "    Given an unlabelled dataset X, a matrix of n x d, and a discriminative model \n",
    "    P(y|x), returns a vector of n entropy values.\n",
    "    \"\"\"\n",
    "    # fill in\n",
    "    print(\"X Shape\",X.shape)\n",
    "    from scipy.stats import entropy\n",
    "    #prob = model.predict_proba(X)   # paper has log \n",
    "    prob = model.predict_proba(X)\n",
    "    #ar = prob.to_numpy()\n",
    "    #print(ar.shape\n",
    "    ent  = entropy(prob,axis=1,base=10)\n",
    "    print(\"Ent shape \",ent.shape)\n",
    "    print(ent)\n",
    "    return ent\n",
    "    #return ent.argmax()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(seed_set)\n",
    "print(X_pool.shape)\n",
    "print(y_pool.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "models_us = pool_based_active_learning(X_pool, y_pool, seed_set, \n",
    "                                 train_logistic_regression, \n",
    "                                 logistic_regression_entropy_select, \n",
    "                                 max_size, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here for evaluation of accuracy and plotting of results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Query by committee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't forget to provide function descriptive comments, like those provided in templates above\n",
    "\n",
    "def query_by_committee_vote_entropy(X, model, **args):\n",
    "    pass\n",
    "\n",
    "def query_by_committee_soft_vote_entropy(X, model, **args):\n",
    "    pass\n",
    "\n",
    "def query_by_committee_KL(X, model, **args):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_committee(X, y, **args):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here for training, evaluation, and plotting code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hierarchical sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python373jvsc74a57bd0256f07a8d45e51611e1e8537f469d6b971ad84699aa9c6eac7ffc833e5f43f4b",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}