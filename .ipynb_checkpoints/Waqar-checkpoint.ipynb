{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP90051 Project 2\n",
    "**Name:** *enter your name here*\n",
    "\n",
    "**Student ID:** *your id here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can add additional imports here\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "# Additional imports\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from numpy import mean\n",
    "from numpy import std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not edit this cell\n",
    "# load the data files (download from the LMS)\n",
    "embedded_images = np.load('images.npy')\n",
    "labels = np.load('labels.npy')\n",
    "\n",
    "# split into pool & testing\n",
    "X_pool, X_test, y_pool, y_test = train_test_split(embedded_images, labels, \n",
    "                                                  test_size=0.5, random_state=1234, shuffle=True)\n",
    "\n",
    "# sample a seed set\n",
    "np.random.seed(1234)\n",
    "label2id = defaultdict(list)\n",
    "for i, label in enumerate(y_pool):\n",
    "    label2id[label].append(i)\n",
    "seed_set = []\n",
    "for label, ids in label2id.items():\n",
    "    seed_set.extend(np.random.choice(ids, size=10, replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9640,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pool.shape\n",
    "y_pool.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Applying logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_regression(X, y, **args):\n",
    "    \"\"\"\n",
    "    Train a logistic regression model on dataset (X, y) and return trained model.\n",
    "    X: matrix of real values, size n x d\n",
    "    y: vector of string labels, size n\n",
    "    args: optional arguments e.g., for hyper-parameters\n",
    "    \"\"\"\n",
    "    # your code here\n",
    "    # run logistic regression model\n",
    "    # NOTE = Find Best parameters \n",
    "    log_reg = LogisticRegression(multi_class='multinomial',  solver='lbfgs')\n",
    "    model = log_reg.fit(X, y)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_logistic_regression_accuracy(Xt, yt, model):\n",
    "    \"\"\"\n",
    "    Apply logistic regression prediction on dataset Xt and evaluate accuracy against yt,\n",
    "    returing the accuracy results as a scalar.\n",
    "    Xt: matrix of real values, size m x d\n",
    "    yt: vector of string labels, size m\n",
    "    \"\"\"\n",
    "    # your code here\n",
    "    y_pred = model.predict(Xt)\n",
    "    # print(\"Accuracy: {}\".format(accuracy_score(yt, y_pred)))\n",
    "    # print(\"Precision: {}\".format(precision_score(yt, y_pred)))\n",
    "    # print(\"Recall: {}\".format(recall_score(yt, y_pred)))\n",
    "    # evaluate the model and collect the scores\n",
    "    # define the model evaluation procedure\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    n_scores = cross_val_score(model, Xt, yt, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    # report the model performance\n",
    "    print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waqar\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.561 (0.016)\n"
     ]
    }
   ],
   "source": [
    "# your code here for training, evaluating & plotting results\n",
    "\n",
    "# Traning model 1 with seed_set -> Subest of y_pool.\n",
    "model1 = train_logistic_regression(X_pool[seed_set],seed_set)\n",
    "\n",
    "# Traning model 2 with max pool \n",
    "#model2 = train_logistic_regression(X_pool,y_pool)\n",
    "\n",
    "# Evaluation of models trained\n",
    "evaluate_logistic_regression_accuracy(X_test,y_test,model1)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Active learning framework with Random selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_select(X, model, **args):\n",
    "    \"\"\"\n",
    "    Given an unlabelled dataset X, a matrix of n x d, and a model (not used)\n",
    "    returns a vector of scores of length n. Each entry reflects the priority \n",
    "    of the corresponding instance. Higher means better.\n",
    "    \"\"\"\n",
    "    # fill in\n",
    "\n",
    "    # Creating a score array using random numbers of length of X \n",
    "    scores = np.random.randint(1,len(X),len(X))\n",
    "    return scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_based_active_learning(X_pool, y_pool, seed_ids,\n",
    "                               train_func, select_func,\n",
    "                               max_size, batch_size, **args):\n",
    "    \"\"\"\n",
    "    Perform an active learning simulation, which starts by training on a seed set,\n",
    "    then iteratively applies the selection function to rank instances in the pool,\n",
    "    selects the top few instances which are included into the training set and the\n",
    "    process repeats. \n",
    "        X_pool: matrix of n x d\n",
    "        y_pool: vector of string labels, size n\n",
    "        seed_ids: initial labelled set set, as a list of indices [0..n-1] into pool\n",
    "        train_func: function which given (X, y, optional args) returns a trained model\n",
    "        select_func: function which given (X, optional args) returns a sequence of scores\n",
    "        max_size: stopping condition for active learning, when labelled data reaches given size\n",
    "        batch_size: number of instances to be labelled in each iteration\n",
    "        args: optional arguments passed to training and selection function\n",
    "    returns the sequence of trained models \n",
    "    \"\"\"\n",
    "    # 1: U = pool of unlabelled instances, {x} \n",
    "    U =  np.delete(X_pool,seed_ids, axis=0)\n",
    "    # 2: L = set of initial labelled instances, {hx,yi} \n",
    "    L = [X_pool[seed_ids],seed_ids]   # L = (x,y)  \n",
    "    # 3: b = number of instances to label in each step \n",
    "    b =  batch\n",
    "    # 4: for t = 1,2,...,T do \n",
    "    for i in range(1,3):  # Loop will run from 300 to 3000 Instances\n",
    "    # 5:  θ(t) = train(L) \n",
    "        Theta_model=train_func(L[0],L[1])\n",
    "    # 6:  score all instances in pool, r = select(U) \n",
    "        r = select_func(U,Theta_model)\n",
    "    # 7:  for all j ∈ argmax(b,r) do \n",
    "        max_indices = np.argpartition(r,-b)[-b:]\n",
    "        for j in max_indices:\n",
    "    # 8:      reveal label y     \n",
    "    # 9:      add hxj,yji to L\n",
    "            L[0] = np.append(L[0],[X_pool[j]], axis=0)\n",
    "            L[1].append(j)\n",
    "            print(\"seed set \",len(seed_set))\n",
    "            print(\"seed id\",len(seed_ids))\n",
    "    # 10:     remove xj from U \n",
    "            U = np.delete(X_pool,L[1],axis=0)   \n",
    "    # 11:    end for \n",
    "    # 12: end for \n",
    "    # 13: return {θ(t)}T t=1\n",
    "    return Theta_model\n",
    "    ########################################## Not Part of Algo ########################\n",
    "    \n",
    "        \n",
    "     #  Calculate and report our model's accuracy.\n",
    "        #model_accuracy = evaluate_logistic_regression_accuracy(X_test,y_test,Theta_model)\n",
    "        #print('Accuracy after query {n}: {acc:0.4f}'.format(n=i + 1, acc=model_accuracy))\n",
    "    # # Save our model's performance for plotting.\n",
    "        #performance_history.append(model_accuracy)\n",
    "\n",
    "    ########################################## Not Part of Algo ########################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seed_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waqar\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed set  301\n",
      "seed id 301\n",
      "seed set  302\n",
      "seed id 302\n",
      "seed set  303\n",
      "seed id 303\n",
      "seed set  304\n",
      "seed id 304\n",
      "seed set  305\n",
      "seed id 305\n",
      "seed set  306\n",
      "seed id 306\n",
      "seed set  307\n",
      "seed id 307\n",
      "seed set  308\n",
      "seed id 308\n",
      "seed set  309\n",
      "seed id 309\n",
      "seed set  310\n",
      "seed id 310\n",
      "seed set  311\n",
      "seed id 311\n",
      "seed set  312\n",
      "seed id 312\n",
      "seed set  313\n",
      "seed id 313\n",
      "seed set  314\n",
      "seed id 314\n",
      "seed set  315\n",
      "seed id 315\n",
      "seed set  316\n",
      "seed id 316\n",
      "seed set  317\n",
      "seed id 317\n",
      "seed set  318\n",
      "seed id 318\n",
      "seed set  319\n",
      "seed id 319\n",
      "seed set  320\n",
      "seed id 320\n",
      "seed set  321\n",
      "seed id 321\n",
      "seed set  322\n",
      "seed id 322\n",
      "seed set  323\n",
      "seed id 323\n",
      "seed set  324\n",
      "seed id 324\n",
      "seed set  325\n",
      "seed id 325\n",
      "seed set  326\n",
      "seed id 326\n",
      "seed set  327\n",
      "seed id 327\n",
      "seed set  328\n",
      "seed id 328\n",
      "seed set  329\n",
      "seed id 329\n",
      "seed set  330\n",
      "seed id 330\n",
      "seed set  331\n",
      "seed id 331\n",
      "seed set  332\n",
      "seed id 332\n",
      "seed set  333\n",
      "seed id 333\n",
      "seed set  334\n",
      "seed id 334\n",
      "seed set  335\n",
      "seed id 335\n",
      "seed set  336\n",
      "seed id 336\n",
      "seed set  337\n",
      "seed id 337\n",
      "seed set  338\n",
      "seed id 338\n",
      "seed set  339\n",
      "seed id 339\n",
      "seed set  340\n",
      "seed id 340\n",
      "seed set  341\n",
      "seed id 341\n",
      "seed set  342\n",
      "seed id 342\n",
      "seed set  343\n",
      "seed id 343\n",
      "seed set  344\n",
      "seed id 344\n",
      "seed set  345\n",
      "seed id 345\n",
      "seed set  346\n",
      "seed id 346\n",
      "seed set  347\n",
      "seed id 347\n",
      "seed set  348\n",
      "seed id 348\n",
      "seed set  349\n",
      "seed id 349\n",
      "seed set  350\n",
      "seed id 350\n",
      "seed set  351\n",
      "seed id 351\n",
      "seed set  352\n",
      "seed id 352\n",
      "seed set  353\n",
      "seed id 353\n",
      "seed set  354\n",
      "seed id 354\n",
      "seed set  355\n",
      "seed id 355\n",
      "seed set  356\n",
      "seed id 356\n",
      "seed set  357\n",
      "seed id 357\n",
      "seed set  358\n",
      "seed id 358\n",
      "seed set  359\n",
      "seed id 359\n",
      "seed set  360\n",
      "seed id 360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waqar\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed set  361\n",
      "seed id 361\n",
      "seed set  362\n",
      "seed id 362\n",
      "seed set  363\n",
      "seed id 363\n",
      "seed set  364\n",
      "seed id 364\n",
      "seed set  365\n",
      "seed id 365\n",
      "seed set  366\n",
      "seed id 366\n",
      "seed set  367\n",
      "seed id 367\n",
      "seed set  368\n",
      "seed id 368\n",
      "seed set  369\n",
      "seed id 369\n",
      "seed set  370\n",
      "seed id 370\n",
      "seed set  371\n",
      "seed id 371\n",
      "seed set  372\n",
      "seed id 372\n",
      "seed set  373\n",
      "seed id 373\n",
      "seed set  374\n",
      "seed id 374\n",
      "seed set  375\n",
      "seed id 375\n",
      "seed set  376\n",
      "seed id 376\n",
      "seed set  377\n",
      "seed id 377\n",
      "seed set  378\n",
      "seed id 378\n",
      "seed set  379\n",
      "seed id 379\n",
      "seed set  380\n",
      "seed id 380\n",
      "seed set  381\n",
      "seed id 381\n",
      "seed set  382\n",
      "seed id 382\n",
      "seed set  383\n",
      "seed id 383\n",
      "seed set  384\n",
      "seed id 384\n",
      "seed set  385\n",
      "seed id 385\n",
      "seed set  386\n",
      "seed id 386\n",
      "seed set  387\n",
      "seed id 387\n",
      "seed set  388\n",
      "seed id 388\n",
      "seed set  389\n",
      "seed id 389\n",
      "seed set  390\n",
      "seed id 390\n",
      "seed set  391\n",
      "seed id 391\n",
      "seed set  392\n",
      "seed id 392\n",
      "seed set  393\n",
      "seed id 393\n",
      "seed set  394\n",
      "seed id 394\n",
      "seed set  395\n",
      "seed id 395\n",
      "seed set  396\n",
      "seed id 396\n",
      "seed set  397\n",
      "seed id 397\n",
      "seed set  398\n",
      "seed id 398\n",
      "seed set  399\n",
      "seed id 399\n",
      "seed set  400\n",
      "seed id 400\n",
      "seed set  401\n",
      "seed id 401\n",
      "seed set  402\n",
      "seed id 402\n",
      "seed set  403\n",
      "seed id 403\n",
      "seed set  404\n",
      "seed id 404\n",
      "seed set  405\n",
      "seed id 405\n",
      "seed set  406\n",
      "seed id 406\n",
      "seed set  407\n",
      "seed id 407\n",
      "seed set  408\n",
      "seed id 408\n",
      "seed set  409\n",
      "seed id 409\n",
      "seed set  410\n",
      "seed id 410\n",
      "seed set  411\n",
      "seed id 411\n",
      "seed set  412\n",
      "seed id 412\n",
      "seed set  413\n",
      "seed id 413\n",
      "seed set  414\n",
      "seed id 414\n",
      "seed set  415\n",
      "seed id 415\n",
      "seed set  416\n",
      "seed id 416\n",
      "seed set  417\n",
      "seed id 417\n",
      "seed set  418\n",
      "seed id 418\n",
      "seed set  419\n",
      "seed id 419\n",
      "seed set  420\n",
      "seed id 420\n"
     ]
    }
   ],
   "source": [
    "batch = 60\n",
    "max_size = 3000\n",
    "models_random = pool_based_active_learning(X_pool, y_pool, seed_set, \n",
    "                                    train_logistic_regression, random_select, \n",
    "                                    max_size, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here for evaluation of accuracy and plotting of results\n",
    "\n",
    "# NOTE: Make Graphs and Check Evaluation Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Uncertainty sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_entropy_select(X, model, **args):\n",
    "    \"\"\"\n",
    "    Given an unlabelled dataset X, a matrix of n x d, and a discriminative model \n",
    "    P(y|x), returns a vector of n entropy values.\n",
    "    \"\"\"\n",
    "    # fill in\n",
    "    #print(X.shape)\n",
    "    from scipy.stats import entropy\n",
    "    prob = model.predict_proba(X)\n",
    "    #ar = prob.to_numpy()\n",
    "    #print(ar.shape\n",
    "    ent  = entropy(ar,axis=1)\n",
    "    #return ent.argmax()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9640, 1000)\n",
      "(9640,)\n"
     ]
    }
   ],
   "source": [
    "len(seed_set)\n",
    "print(X_pool.shape)\n",
    "print(y_pool.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waqar\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9340, 300)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to_numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-aa84a4686c1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m                                  \u001b[0mtrain_logistic_regression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                  \u001b[0mlogistic_regression_entropy_select\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                                  max_size, batch)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-35-78da4db082d3>\u001b[0m in \u001b[0;36mpool_based_active_learning\u001b[1;34m(X_pool, y_pool, seed_ids, train_func, select_func, max_size, batch_size, **args)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mTheta_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# 6:  score all instances in pool, r = select(U)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTheta_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;31m# 7:  for all j ∈ argmax(b,r) do\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mmax_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-62-527ecb9e0ec5>\u001b[0m in \u001b[0;36mlogistic_regression_entropy_select\u001b[1;34m(X, model, **args)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m#print(ar.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0ment\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to_numpy'"
     ]
    }
   ],
   "source": [
    "models_us = pool_based_active_learning(X_pool, y_pool, seed_set, \n",
    "                                 train_logistic_regression, \n",
    "                                 logistic_regression_entropy_select, \n",
    "                                 max_size, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here for evaluation of accuracy and plotting of results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Query by committee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't forget to provide function descriptive comments, like those provided in templates above\n",
    "\n",
    "def query_by_committee_vote_entropy(X, model, **args):\n",
    "    pass\n",
    "\n",
    "def query_by_committee_soft_vote_entropy(X, model, **args):\n",
    "    pass\n",
    "\n",
    "def query_by_committee_KL(X, model, **args):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_committee(X, y, **args):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here for training, evaluation, and plotting code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hierarchical sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
